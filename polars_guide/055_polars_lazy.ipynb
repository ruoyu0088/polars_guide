{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb7f1a45-436e-46e9-8b5b-99a3870eaea7",
   "metadata": {},
   "source": [
    "# 遅延演算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e1f3774-f6da-4b35-aa0e-35dc445b2e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import threading\n",
    "from helper.jupyter import row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55181427-9f5a-479b-9429-965ff14bff0a",
   "metadata": {},
   "source": [
    "Polarsの遅延演算は、クエリを即時実行せず「実行計画」として蓄積し、最適化後に一括実行する仕組みです。主なメリットは以下です。\n",
    "\n",
    "- **自動最適化**: 不要な計算の省略・操作順序の最適化\n",
    "- **メモリ効率**: 必要なタイミングでのみ処理実行\n",
    "- **大規模データ対応**: メモリ不足のリスク低減"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff82809-5386-4051-a8ba-da03d415cbfb",
   "metadata": {},
   "source": [
    "## 基本フロー  \n",
    "\n",
    "1. `DataFrame.lazy()` メソッドで `LazyFrame` に変換するか、`scan_*()` 関数で直接ファイルから `LazyFrame` を取得します。  \n",
    "2. フィルタや集計などの処理チェーンを構築します。  \n",
    "3. `collect()` で最終実行するか、`explain()` で実行計画を確認します。  \n",
    "\n",
    "以下の例では、`df.lazy()` で `LazyFrame` に変換した後、`DataFrame` と同じメソッドを使って処理チェーンを構築します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd2c7b8c-a379-4485-896a-7b31dea74f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\n",
    "    \"product\": [\"A\", \"B\", \"C\", \"A\", \"B\"],\n",
    "    \"category\": [\"X\", \"Y\", \"X\", \"Y\", \"X\"],\n",
    "    \"price\": [100, 200, 150, 300, 250],\n",
    "    \"quantity\": [5, 3, 4, 2, 6]\n",
    "})\n",
    "\n",
    "lazy_operations = (\n",
    "    df.lazy()\n",
    "    .filter(pl.col(\"price\") > 150)\n",
    "    .filter(pl.col(\"price\") < 280)\n",
    "    .group_by(\"category\")    \n",
    "    .agg(pl.col(\"quantity\").sum().alias(\"total_quantity\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a54b6c3-7b95-4044-9f72-d889a01fd404",
   "metadata": {},
   "source": [
    "`explain()` を使うと、実行計画を分析できます。`optimized` 引数を `True` にすると最適化後の計画を確認できます。以下の出力例のように、最適化後は 2 つの `FILTER` が 1 つの `SELECTION` に統合されます。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dbc81d9-c2b6-4a26-abfe-7013595b9075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGGREGATE\n",
      "\t[col(\"quantity\").sum().alias(\"total_quantity\")] BY [col(\"category\")] FROM\n",
      "  FILTER [(col(\"price\")) < (280)] FROM\n",
      "    FILTER [(col(\"price\")) > (150)] FROM\n",
      "      DF [\"product\", \"category\", \"price\", \"quantity\"]; PROJECT */4 COLUMNS; SELECTION: None\n",
      "AGGREGATE\n",
      "\t[col(\"quantity\").sum().alias(\"total_quantity\")] BY [col(\"category\")] FROM\n",
      "  DF [\"product\", \"category\", \"price\", \"quantity\"]; PROJECT 3/4 COLUMNS; SELECTION: [([(col(\"price\")) > (150)]) & ([(col(\"price\")) < (280)])]\n"
     ]
    }
   ],
   "source": [
    "print(lazy_operations.explain(optimized=False))\n",
    "print(lazy_operations.explain(optimized=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559c7972-963e-4034-acc3-a6ada12167bc",
   "metadata": {},
   "source": [
    "演算結果を取得するには `collect()` メソッドを使用します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e67149e-2fd1-488b-9526-04251b3c2f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>category</th><th>total_quantity</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;X&quot;</td><td>6</td></tr><tr><td>&quot;Y&quot;</td><td>3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌──────────┬────────────────┐\n",
       "│ category ┆ total_quantity │\n",
       "│ ---      ┆ ---            │\n",
       "│ str      ┆ i64            │\n",
       "╞══════════╪════════════════╡\n",
       "│ X        ┆ 6              │\n",
       "│ Y        ┆ 3              │\n",
       "└──────────┴────────────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lazy_operations.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f36e5e-e0fd-4e71-9410-4a94ab98a9bb",
   "metadata": {},
   "source": [
    "`collect()` 実行後も処理チェーンは保持されるため、`sort()` を追加して再実行することもできます。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96b507c1-4038-4f07-82e1-c65bf738e264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>category</th><th>total_quantity</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;X&quot;</td><td>6</td></tr><tr><td>&quot;Y&quot;</td><td>3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌──────────┬────────────────┐\n",
       "│ category ┆ total_quantity │\n",
       "│ ---      ┆ ---            │\n",
       "│ str      ┆ i64            │\n",
       "╞══════════╪════════════════╡\n",
       "│ X        ┆ 6              │\n",
       "│ Y        ┆ 3              │\n",
       "└──────────┴────────────────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lazy_operations.sort(\"total_quantity\", descending=True).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c05d51-0d13-4a70-82c6-8467c2c0f138",
   "metadata": {},
   "source": [
    "次のテーブルで、遅延演算と即時実行の比較をまとめます。\n",
    "\n",
    "| 特徴                | 遅延演算 (Lazy)       | 即時実行 (Eager)       |\n",
    "|---------------------|-----------------------|------------------------|\n",
    "| 実行タイミング       | `collect()` で一括実行 | 各操作ごとに即時実行   |\n",
    "| 最適化              | 自動的に実施          | なし                   |\n",
    "| メモリ効率          | 高い                  | 低い（中間データ保持） |\n",
    "| 主な用途            | 大規模データ・複雑処理 | 小規模データ・簡易処理 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6fed23-92ce-4144-8ba3-731a3955cfd7",
   "metadata": {},
   "source": [
    "## ストリーミング処理\n",
    "\n",
    "\n",
    "Polarsのストリーミング処理は、大規模なデータセットを効率的に処理するための仕組みで、データを「チャンク」と呼ばれる小さな部分に分割し、逐次処理を行います。この手法により、メモリ消費を抑えながら高速なデータ処理が可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03da3c60-3d04-4021-95e3-0b5e9cf5ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "df = pl.LazyFrame({\n",
    "    \"A\":np.random.randn(n),\n",
    "    \"B\":np.random.randn(n),\n",
    "    \"C\":np.random.randint(0, 10, n)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b01843-3baf-44a7-9876-05b7292c73db",
   "metadata": {},
   "source": [
    "演算をストリーミングで処理できるかどうかを調べるには、`.explain(streaming=True)`を使用します。`STREAMING:`の下に表示される演算は、すべてストリーミングで処理可能であることを示しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3272f0b3-1820-4e23-b036-7928ddd9b056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STREAMING:\n",
      "  AGGREGATE\n",
      "  \t[col(\"B\").mean()] BY [col(\"C\")] FROM\n",
      "    FILTER [(col(\"A\")) > (0.5)] FROM\n",
      "      DF [\"A\", \"B\", \"C\"]; PROJECT 3/3 COLUMNS\n"
     ]
    }
   ],
   "source": [
    "df2 = df.filter(pl.col('A') > 0.5).group_by('C').agg(pl.col('B').mean())\n",
    "print(df2.explain(streaming=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff9f620-a9cc-46ea-b276-24ef50bce571",
   "metadata": {},
   "source": [
    "次の出力では、`group_by()`の`maintain_order=True`を設定した場合、`group_by()`がストリーミング処理できなくなることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "180c0705-e34a-4d56-866d-9447aa308f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGGREGATE\n",
      "\t[col(\"B\").mean()] BY [col(\"C\")] FROM\n",
      "  STREAMING:\n",
      "    FILTER [(col(\"A\")) > (0.5)] FROM\n",
      "      DF [\"A\", \"B\", \"C\"]; PROJECT 3/3 COLUMNS\n"
     ]
    }
   ],
   "source": [
    "df3 = df.filter(pl.col('A') > 0.5).group_by('C', maintain_order=True).agg(pl.col('B').mean())\n",
    "print(df3.explain(streaming=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7f4cd8-6912-48b5-bdd2-e4df99db558c",
   "metadata": {},
   "source": [
    "ストリーミング処理を使って結果を計算する場合、`.collect(streaming=True)`を呼び出します。この方法では、可能であればストリーミング処理が適用され、効率的に結果を計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cad83ab-8119-448b-af8d-cca7cecb7360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>C</th><th>B</th></tr><tr><td>i32</td><td>f64</td></tr></thead><tbody><tr><td>4</td><td>-0.207007</td></tr><tr><td>7</td><td>0.241421</td></tr><tr><td>9</td><td>-0.114259</td></tr><tr><td>0</td><td>-0.081423</td></tr><tr><td>3</td><td>-0.15736</td></tr><tr><td>2</td><td>-0.22622</td></tr><tr><td>1</td><td>0.301292</td></tr><tr><td>5</td><td>-0.095738</td></tr><tr><td>6</td><td>-0.17092</td></tr><tr><td>8</td><td>0.130623</td></tr></tbody></table></div></td><td><div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>C</th><th>B</th></tr><tr><td>i32</td><td>f64</td></tr></thead><tbody><tr><td>3</td><td>-0.15736</td></tr><tr><td>0</td><td>-0.081423</td></tr><tr><td>9</td><td>-0.114259</td></tr><tr><td>2</td><td>-0.22622</td></tr><tr><td>4</td><td>-0.207007</td></tr><tr><td>7</td><td>0.241421</td></tr><tr><td>8</td><td>0.130623</td></tr><tr><td>5</td><td>-0.095738</td></tr><tr><td>6</td><td>-0.17092</td></tr><tr><td>1</td><td>0.301292</td></tr></tbody></table></div></td></tr></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row(df2.collect(streaming=True), df3.collect(streaming=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89de079-151d-4d50-8481-c3b2df16f43e",
   "metadata": {},
   "source": [
    "次のコードでは、ストリーミング処理を観察するために、`map_batches()`を使用してデータをユーザー関数に渡します。このユーザー関数内で、データの名前、データの長さ、および処理しているスレッドを出力します。\n",
    "\n",
    "```{tip}\n",
    "`agg_list`引数がデフォルト値の`False`の場合、`map_batches()`の演算をストリーミング処理することはできません。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7967e95c-cd3a-4e1f-83ae-f97ce8c884d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STREAMING:\n",
      "  FILTER [(col(\"A\")) > (0.5)] FROM\n",
      "     SELECT [col(\"A\").map_list(), col(\"B\").map_list()] FROM\n",
      "      DF [\"A\", \"B\", \"C\"]; PROJECT 2/3 COLUMNS\n"
     ]
    }
   ],
   "source": [
    "lock = threading.Lock()\n",
    "def f(s):\n",
    "    with lock:\n",
    "        print(s.name, s.shape, threading.current_thread())\n",
    "        return s\n",
    "\n",
    "df4 = df.select(pl.col('A', 'B').map_batches(f, agg_list=True)).filter(pl.col('A') > 0.5)\n",
    "print(df4.explain(streaming=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53b5b4-a993-4bee-a745-afdfa5424c65",
   "metadata": {},
   "source": [
    "次のコードを実行すると、以下のような出力から、A列とB列がそれぞれおよそ長さ83のチャンクに分割され、異なるスレッドで並列処理されていることが確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72d52e27-29fe-4e06-ae21-5988f7c1c413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A (83,) <_DummyThread(Dummy-13, started daemon 32484)>\n",
      "A (83,) <_DummyThread(Dummy-3, started daemon 5548)>\n",
      "A (83,) <_DummyThread(Dummy-11, started daemon 31196)>\n",
      "A (83,) <_DummyThread(Dummy-14, started daemon 29732)>\n",
      "B (83,) <_DummyThread(Dummy-14, started daemon 29732)>\n",
      "A (83,) <_DummyThread(Dummy-12, started daemon 32148)>\n",
      "A (83,) <_DummyThread(Dummy-6, started daemon 29448)>\n",
      "B (83,) <_DummyThread(Dummy-6, started daemon 29448)>\n",
      "A (83,) <_DummyThread(Dummy-10, started daemon 24416)>\n",
      "B (83,) <_DummyThread(Dummy-10, started daemon 24416)>\n",
      "A (83,) <_DummyThread(Dummy-9, started daemon 30848)>\n",
      "B (83,) <_DummyThread(Dummy-9, started daemon 30848)>\n",
      "B (83,) <_DummyThread(Dummy-13, started daemon 32484)>\n",
      "B (83,) <_DummyThread(Dummy-3, started daemon 5548)>\n",
      "B (83,) <_DummyThread(Dummy-11, started daemon 31196)>\n",
      "A (87,) <_DummyThread(Dummy-7, started daemon 25668)>\n",
      "B (87,) <_DummyThread(Dummy-7, started daemon 25668)>\n",
      "A (83,) <_DummyThread(Dummy-8, started daemon 32692)>\n",
      "A (83,) <_DummyThread(Dummy-4, started daemon 34336)>\n",
      "B (83,) <_DummyThread(Dummy-4, started daemon 34336)>\n",
      "A (83,) <_DummyThread(Dummy-5, started daemon 25324)>\n",
      "B (83,) <_DummyThread(Dummy-5, started daemon 25324)>\n",
      "B (83,) <_DummyThread(Dummy-12, started daemon 32148)>\n",
      "B (83,) <_DummyThread(Dummy-8, started daemon 32692)>\n"
     ]
    }
   ],
   "source": [
    "df4.collect(streaming=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b1809d-eaf8-44b6-8b49-8ab3ab19d514",
   "metadata": {},
   "source": [
    "また、`streaming`引数を省略した場合（デフォルト値は`False`）、A列とB列はチャンクに分割されず、それぞれ全体を別々のスレッドで処理することがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6395f86-cbc8-466f-b049-891757dac647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A (1000,) <_DummyThread(Dummy-7, started daemon 25668)>\n",
      "B (1000,) <_DummyThread(Dummy-13, started daemon 32484)>\n"
     ]
    }
   ],
   "source": [
    "df4.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7442b74b-d5f5-4be6-abc5-3c6fbc33d12d",
   "metadata": {},
   "source": [
    "`scan_*()`関数を使用してファイルからデータを読み込んで処理する場合、事前にデータの長さがわからないため、次のコードの出力からも分かるように、チャンクを均等に分割することができません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a31b25c-79f4-4a10-b87d-ecdb21e7ca84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STREAMING:\n",
      "  FILTER [(col(\"A\")) > (0.5)] FROM\n",
      "     SELECT [col(\"A\").map_list(), col(\"B\").map_list()] FROM\n",
      "      Csv SCAN [data/streaming_test.csv]\n",
      "      PROJECT 2/3 COLUMNS\n",
      "A (99,) <_DummyThread(Dummy-6, started daemon 29448)>\n",
      "B (99,) <_DummyThread(Dummy-6, started daemon 29448)>\n",
      "A (99,) <_DummyThread(Dummy-10, started daemon 24416)>\n",
      "B (99,) <_DummyThread(Dummy-10, started daemon 24416)>\n",
      "A (98,) <_DummyThread(Dummy-4, started daemon 34336)>\n",
      "B (98,) <_DummyThread(Dummy-4, started daemon 34336)>\n",
      "A (99,) <_DummyThread(Dummy-7, started daemon 25668)>\n",
      "A (99,) <_DummyThread(Dummy-11, started daemon 31196)>\n",
      "B (99,) <_DummyThread(Dummy-11, started daemon 31196)>\n",
      "A (99,) <_DummyThread(Dummy-8, started daemon 32692)>\n",
      "B (99,) <_DummyThread(Dummy-8, started daemon 32692)>\n",
      "A (99,) <_DummyThread(Dummy-14, started daemon 29732)>\n",
      "B (99,) <_DummyThread(Dummy-14, started daemon 29732)>\n",
      "A (99,) <_DummyThread(Dummy-13, started daemon 32484)>\n",
      "B (99,) <_DummyThread(Dummy-13, started daemon 32484)>\n",
      "A (99,) <_DummyThread(Dummy-9, started daemon 30848)>\n",
      "B (99,) <_DummyThread(Dummy-9, started daemon 30848)>\n",
      "A (11,) <_DummyThread(Dummy-12, started daemon 32148)>\n",
      "B (11,) <_DummyThread(Dummy-12, started daemon 32148)>\n",
      "A (99,) <_DummyThread(Dummy-3, started daemon 5548)>\n",
      "B (99,) <_DummyThread(Dummy-3, started daemon 5548)>\n",
      "B (99,) <_DummyThread(Dummy-7, started daemon 25668)>\n"
     ]
    }
   ],
   "source": [
    "df.collect().write_csv('data/streaming_test.csv')\n",
    "df5 = pl.scan_csv('data/streaming_test.csv', cache=False, ).select(pl.col('A', 'B').map_batches(f, agg_list=True)).filter(pl.col('A') > 0.5)\n",
    "print(df5.explain(streaming=True))\n",
    "df5.collect(streaming=True, );"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
